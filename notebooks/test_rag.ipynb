{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM and RAG testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! It looks like you might have had a bit of a keyboard mishap. How can I assist you today?\n",
      "Failure\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "with open(\"../.env\", \"r\") as f:\n",
    "    os.environ.update(\n",
    "        dict(line.strip().split(\"=\") for line in f if not line.startswith(\"#\"))\n",
    "    )\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "message = \"Hello, how are you today?\"\n",
    "message = \"\".join(\"\\u00a0\" if i % 2 else c for i, c in enumerate(message))\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    ")\n",
    "print(completion.choices[0].message.content)\n",
    "if \"\\u00a0\" in completion.choices[0].message.content:\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failure\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8576 520\n",
      "{'doc_id': '6f86094c-47fe-43de-a77a-e8c34c69c997', 'contents': \"# Rag-Driver: Generalisable Driving Explanations With Retrieval-Augmented In-Context Learning In Multi-Modal Large Language Model\\n\\nJianhao Yuan1, Shuyang Sun1, Daniel Omeiza1, Bo Zhao2, Paul Newman1, Lars Kunze1, Matthew Gadd1\\n1 University of Oxford 2 Beijing Academy of Artificial Intelligence\\n{jianhaoyuan,kevinsun,daniel,pnewman,lars,mattgadd}@robots.ox.ac.uk  \\nAbstract—Robots powered by 'blackbox' models need to provide\\nhuman-understandable explanations which we can trust. Hence,\\nexplainability plays a critical role in trustworthy autonomous\\ndecision-making to foster transparency and acceptance among\\nend users, especially in complex autonomous driving. Recent\\nadvancements in Multi-Modal Large Language models (MLLMs)\\nhave shown promising potential in enhancing the explainability\\nas a driving agent by producing control predictions along with\\nnatural language explanations. However, severe data scarcity\\ndue to expensive annotation costs and significant domain gaps\\nbetween different datasets makes the development of a robust and\\ngeneralisable system an extremely challenging task. Moreover, the\\nprohibitively expensive training requirements of MLLM and the\\nunsolved problem of catastrophic forgetting further limit their\\ngeneralisability post-deployment. To address these challenges, we\\npresent RAG-Driver, a novel retrieval-augmented multi-modal\\nlarge language model that leverages in-context learning for high-\\nperformance, explainable, and generalisable autonomous driving.\\nBy grounding in retrieved expert demonstration, we empirically\\nvalidate that RAG-Driver achieves state-of-the-art performance in\\nproducing driving action explanations, justifications, and control\\nsignal prediction. More importantly, it exhibits exceptional zero-\\nshot generalisation capabilities to unseen environments without  \\nfurther training endeavours1.\\nIndex Terms—Autonomous driving, multi-modal language\\nmodel, end-to-end driving, domain generalisation\", 'metadata': {'creation_datetime': '2024-03-04', 'file_name': '2402.10828v1.md', 'file_path': 'paper_data/2402.10828v1.md', 'file_size': 64885, 'file_type': None, 'last_accessed_datetime': '2024-03-04', 'last_modified_datetime': '2024-02-22'}}\n",
      "# Rag-Driver: Generalisable Driving Explanations With Retrieval-Augmented In-Context Learning In Multi-Modal Large Language Model\n",
      "\n",
      "Jianhao Yuan1, Shuyang Sun1, Daniel Omeiza1, Bo Zhao2, Paul Newman1, Lars Kunze1, Matthew Gadd1\n",
      "1 University of Oxford 2 Beijing Academy of Artificial Intelligence\n",
      "{jianhaoyuan,kevinsun,daniel,pnewman,lars,mattgadd}@robots.ox.ac.uk  \n",
      "Abstract—Robots powered by 'blackbox' models need to provide\n",
      "human-understandable explanations which we can trust. Hence,\n",
      "explainability plays a critical role in trustworthy autonomous\n",
      "decision-making to foster transparency and acceptance among\n",
      "end users, especially in complex autonomous driving. Recent\n",
      "advancements in Multi-Modal Large Language models (MLLMs)\n",
      "have shown promising potential in enhancing the explainability\n",
      "as a driving agent by producing control predictions along with\n",
      "natural language explanations. However, severe data scarcity\n",
      "due to expensive annotation costs and significant domain gaps\n",
      "between different datasets makes the development of a robust and\n",
      "generalisable system an extremely challenging task. Moreover, the\n",
      "prohibitively expensive training requirements of MLLM and the\n",
      "unsolved problem of catastrophic forgetting further limit their\n",
      "generalisability post-deployment. To address these challenges, we\n",
      "present RAG-Driver, a novel retrieval-augmented multi-modal\n",
      "large language model that leverages in-context learning for high-\n",
      "performance, explainable, and generalisable autonomous driving.\n",
      "By grounding in retrieved expert demonstration, we empirically\n",
      "validate that RAG-Driver achieves state-of-the-art performance in\n",
      "producing driving action explanations, justifications, and control\n",
      "signal prediction. More importantly, it exhibits exceptional zero-\n",
      "shot generalisation capabilities to unseen environments without  \n",
      "further training endeavours1.\n",
      "Index Terms—Autonomous driving, multi-modal language\n",
      "model, end-to-end driving, domain generalisation\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "corpus = load_dataset(\"MarkrAI/AutoRAG-evaluation-2024-LLM-paper-v1\", \"corpus\")\n",
    "qa = load_dataset(\"MarkrAI/AutoRAG-evaluation-2024-LLM-paper-v1\", \"qa\")\n",
    "\n",
    "print(len(corpus[\"train\"]), len(qa[\"train\"]))\n",
    "print(corpus[\"train\"][0])\n",
    "print(corpus[\"train\"][0][\"contents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.021245203912258148, 0.013545427471399307, 0.0005057807429693639, -0.01877303421497345, 0.007880039513111115, -0.03543442487716675, -0.004818798508495092, 0.0417693592607975, -0.023987766355276108, 0.034224092960357666, 0.024322539567947388, -0.06886021047830582, -0.023910511285066605, 0.01507765706628561, -0.000727084930986166, -0.03764907643198967, 0.00640896987169981, 0.0001486761902924627, -0.003553743241354823, 0.01944258064031601, 0.04447329416871071, -0.016210734844207764, 0.01883741468191147, 0.004432522226125002, -0.006849968805909157, -0.04684245586395264, 0.04547761380672455, 0.024876203387975693, 0.00895517598837614, -0.031133880838751793, 0.03365755453705788, -0.033451538532972336, -0.037365809082984924, -0.013107647188007832, -0.028893478214740753, 0.020125003531575203, 0.01703479140996933, 0.009064620360732079, -0.0200091190636158, -0.0013745003379881382, 0.013905951753258705, -0.03654175251722336, -0.0005246921791695058, 0.02760588936507702, 0.019635718315839767, 0.043623484671115875, 0.014047586359083652, -5.6181092077167705e-05, -0.021670108661055565, 0.021708736196160316, -0.057014402002096176, -0.029434265568852425, 0.008143994957208633, 0.05240483582019806, -0.06870570033788681, 0.034996647387742996, 0.02065291441977024, 0.004422865342348814, 0.024824699386954308, -0.06448241323232651, -0.03950320556759834, -0.04341747239232063, -0.01097668893635273, 0.020730169489979744, -0.008517395704984665, -0.013738565146923065, -0.02613803930580616, 0.024914830923080444, -0.03391507267951965, 0.013062581419944763, 0.0018026233883574605, -0.01626223884522915, 0.030541591346263885, 0.004982965998351574, 0.005391775164753199, -0.01017194613814354, -0.0141892209649086, 0.06726360321044922, -0.05057646334171295, -0.03785509243607521, -0.0019120683427900076, -0.009631159715354443, 0.006386436987668276, -0.04053327441215515, -0.02597065269947052, -0.011955255642533302, -0.005082754418253899, -0.006734086200594902, 0.004731886554509401, -0.05716891214251518, -0.0229190681129694, 0.020691541954874992, 0.001412323210388422, 0.020704416558146477, 0.031571660190820694, 0.038704898208379745, 0.008839292451739311, 0.005266235675662756, 0.0669545829296112, 0.01469138078391552, -0.01362268254160881, -0.06510045379400253, 0.019365325570106506, -0.012270715087652206, 0.03731430321931839, -0.02161860466003418, -0.002803723094984889, 0.006038788240402937, -0.018399635329842567, -0.009560341946780682, -0.06736661493778229, 0.019764477387070656, -0.020331017673015594, -0.003001689910888672, -0.005011936649680138, -0.03548593074083328, -0.04375224560499191, -0.03283349797129631, -0.02165723219513893, -0.008749161846935749, -0.017382439225912094, -0.011671986430883408, 0.017292309552431107, -0.05474824830889702, 0.038601893931627274, -0.01984173245728016, 0.018850291147828102, -0.038138359785079956, -0.021773114800453186, 0.003997961059212685, -0.006985165644437075, 0.03283349797129631, -0.0021245204843580723, -0.03952895477414131, -0.05598433315753937, -0.01106038223952055, -0.00478660874068737, -0.009367203339934349, -0.0601046159863472, -0.005929343402385712, -0.011240644380450249, -0.03394082188606262, -0.0450398325920105, 0.040043991059064865, -0.05660237371921539, -0.014214972965419292, 0.00887148268520832, 0.00555594265460968, -0.006099948659539223, 0.03298800811171532, -0.028635960072278976, -0.03198368847370148, -0.04527159780263901, 0.023215213790535927, -0.020923307165503502, -0.036361489444971085, -0.02737412415444851, 0.051452022045850754, 0.01933957450091839, -0.053666673600673676, 0.024554306641221046, 0.05279111489653587, -0.0015467152697965503, -0.011350089684128761, -0.03463612124323845, 0.056808389723300934, -0.051761042326688766, -0.011388717219233513, -0.03309101611375809, -0.028893478214740753, -0.015875961631536484, -0.030464336276054382, -0.055366288870573044, -0.029125243425369263, 0.00018006114987656474, 0.006344590801745653, 0.0015676385955885053, -0.029640279710292816, 0.022597171366214752, -0.010320018976926804, -0.01626223884522915, 0.014060462825000286, -0.027219614014029503, 0.0014815310714766383, -0.040172748267650604, -0.03551167994737625, 0.006322057917714119, 0.011594731360673904, 0.012290028855204582, 0.013777192682027817, -0.02121945284307003, 0.07493762671947479, 0.04120282083749771, 0.0493403784930706, 0.03159741312265396, -0.004776951856911182, 0.05552079901099205, -0.03494514152407646, 0.027992166578769684, -0.026627322658896446, 0.04091954976320267, 0.04776952043175697, 0.028017917647957802, -0.08086053282022476, -0.039271436631679535, -0.001034898916259408, 0.0008240563911385834, 0.028841974213719368, -0.044499047100543976, -0.016506880521774292, 0.021103570237755775, -0.006669706664979458, 0.0500614270567894, 0.010036749765276909, -0.05459373816847801, -0.010519594885408878, -0.026987846940755844, 0.017330937087535858, 0.060156118124723434, 0.012367283925414085, -0.014897394925355911, 0.011974569410085678, 0.0038724213372915983, 0.0019619623199105263, -0.037803586572408676, 0.03149440512061119, 0.054439228028059006, -0.03551167994737625, 0.045735131949186325, -0.01579870656132698, 0.05809597671031952, 0.009013117291033268, -0.055469296872615814, -0.04867083206772804, 0.04388100281357765, -0.024412671104073524, 0.0024045708123594522, -0.041692104190588, 0.03476487845182419, -0.01452399417757988, 0.01724080555140972, 0.044524796307086945, 0.01413771789520979, -0.050782475620508194, 0.007455135229974985, 0.013983206823468208, -0.04725448414683342, -0.03285925090312958, 0.03775208443403244, -0.02703935094177723, 0.034558866173028946, -0.05003567412495613, -0.029460016638040543, -0.020459774881601334, -0.03806110471487045, 0.031674668192863464, -0.024206656962633133, -0.006650392897427082, -0.04076503962278366, -0.005201856140047312, -0.053563665598630905, -0.005475468467921019, -0.01452399417757988, 0.022404033690690994, 0.013738565146923065, -0.01047452911734581, 0.006315619684755802, 0.02894498221576214, -0.011568979360163212, 0.01467850524932146, 0.0011202016612514853, -0.025378363206982613, -0.026781832799315453, 0.017730088904500008, -0.08858606219291687, 0.005591351538896561, 0.03059309348464012, -0.00512781972065568, -0.0054851253516972065, 0.0008264706120826304, 0.013313661329448223, -0.003220579819753766, 0.08698945492506027, 0.01686740480363369, 0.0022967352997511625, 0.010403712280094624, 0.01883741468191147, -0.0006538533489219844, -0.025558624416589737, -0.043597735464572906, 0.01592746563255787, -0.02701359987258911, 0.02345985546708107, -0.03564044088125229, 0.0029904234688729048, -0.008581775240600109, 0.034558866173028946, 0.01783309504389763, 0.042490407824516296, 0.01937820203602314, 0.020060623064637184, 0.01154322735965252, -0.028017917647957802, -0.02727111615240574, -0.011053944006562233, 0.03298800811171532, -0.053769681602716446, -0.05794146656990051, -0.007474448997527361, -0.021129321306943893, -0.01994474045932293, -0.028996484354138374, -0.014961774460971355, 0.02680758573114872, -0.02904798835515976, -0.016481127589941025, 0.042953941971063614, 0.006112824659794569, 0.02088467963039875, -0.038138359785079956, -0.01887604221701622, -0.015618444420397282, -0.0001942447415785864, -0.01693178340792656, -0.04689396172761917, -0.02145121805369854, 0.018090613186359406, -0.0027184204664081335, -0.012290028855204582, -0.024554306641221046, -0.013326536864042282, 0.026730330660939217, 0.0030773356556892395, -0.008601089008152485, 0.018232248723506927, -0.06381286680698395, -0.07143539190292358, 0.00921913143247366, -0.006434721872210503, -0.005369242746382952, -0.03718554601073265, 0.036490246653556824, -0.04174360632896423, 0.017614206299185753, 0.004129938781261444, 0.03337428346276283, 0.008858606219291687, 0.046069905161857605, 0.034661874175071716, 0.030206818133592606, 0.02915099635720253, -0.041151318699121475, -0.00019474769942462444, 0.019056305289268494, 0.005819898564368486, 0.007519514765590429, -0.02325384132564068, 0.006991603411734104, -0.02915099635720253, -0.0001851913839345798, -0.012830816209316254, 0.032550226897001266, -0.017356688156723976, 0.013983206823468208, -4.096642805961892e-05, 0.0317261703312397, -0.03878215327858925, 0.028893478214740753, 0.020640037953853607, 0.014614125713706017, 0.01927519403398037, -0.00957321748137474, -0.0592290535569191, 0.03481638431549072, -0.03218970447778702, -0.002209823112934828, -0.022313902154564857, -0.006135357543826103, -0.008337133564054966, -0.007017355412244797, -0.004867083393037319, -0.008929423987865448, -0.023704497143626213, -0.030103810131549835, 0.013493923470377922, 0.01941682957112789, 0.004371361806988716, 0.0027071540243923664, 0.006338152568787336, -0.0005206684581935406, -0.06314332038164139, -0.04053327441215515, -0.047743767499923706, 0.014408111572265625, -0.024644436314702034, -0.00516966637223959, 0.016223611310124397, -0.005951876286417246, 0.04738324508070946, 0.04354622960090637, 0.004599908832460642, -0.022313902154564857, -0.01147884875535965, 0.0031562005169689655, 0.007268434856086969, 0.058456502854824066, 0.018283750861883163, 0.03582070395350456, -0.053769681602716446, -0.001090426230803132, 0.05474824830889702, -0.04903135821223259, 0.026047907769680023, -0.011420906521379948, -0.001586952363140881, -0.006804903503507376, -0.0008594651008024812, 0.03170042112469673, 0.04346897453069687, 0.034919388592243195, 0.03919418156147003, -0.012244963087141514, -0.016893155872821808, -0.017086295410990715, -0.007860725745558739, 0.03571769595146179, 0.04467931017279625, 0.003527991473674774, 0.03976072371006012, -0.06247377768158913, -0.025777515023946762, 0.07225944846868515, 0.02379462867975235, -0.009405831806361675, 0.001950695994310081, -0.013416668400168419, 0.0341983400285244, 0.012109766714274883, -0.042052630335092545, -0.03741731122136116, 0.039812225848436356, -0.04318570718169212, -0.03582070395350456, -0.024206656962633133, -0.0029373103752732277, -0.01703479140996933, -0.03976072371006012, 0.04949488863348961, 0.005749081261456013, -0.01017194613814354, 0.019094932824373245, 0.01194881834089756, -0.00443574134260416, 0.030206818133592606, -0.05989859998226166, -0.025558624416589737, 0.06077415868639946, -0.006714771967381239, 0.024554306641221046, -0.004487244877964258, -0.003627779660746455, 0.017227929085493088, -0.031236888840794563, -0.021167948842048645, 0.02559725195169449, 0.008208374492824078, -0.003255988471210003, -0.02115507237613201, 0.003991523291915655, -0.006901472341269255, -0.0015185492811724544, 0.020730169489979744, -0.004171785432845354, -0.017459694296121597, -0.0341983400285244, 0.011079696007072926, 0.003914267756044865, -0.08286917209625244, -0.017717212438583374, -0.016043348237872124, -0.059589579701423645, -0.0052115130238235, -0.006714771967381239, 0.0036342174280434847, 0.029511520639061928, 0.055366288870573044, -0.00018830977205652744, 0.01653263159096241, -0.007010917644947767, -0.006547385826706886, -0.02542986534535885, 0.005498001351952553, 0.021966254338622093, -0.013545427471399307, -0.036696262657642365, 0.015167788602411747, 0.0408938005566597, -0.044293031096458435, 0.020858928561210632, -0.01447249110788107, -0.000535958562977612, -0.02255854383111, -0.007448697462677956, 0.011105448007583618, -0.032009441405534744, -0.009508838877081871, -0.013828696683049202, -0.013584055006504059, 0.00021868880139663815, 0.028970733284950256, -0.07138388603925705, 0.01864427700638771, -0.01697041094303131, 0.017717212438583374, 0.006611764896661043, 0.0325244776904583, -0.010448778048157692, 0.029099492356181145, 0.01208401471376419, 0.050318945199251175, -0.005649292841553688, -0.011021754704415798, 0.0027860188856720924, 0.013172026723623276, 0.021695859730243683, 0.014948897995054722, -0.0017929665045812726, -0.045400358736515045, -0.018554145470261574, 0.0006703505641780794, 0.017987607046961784, 0.00846589170396328, 0.0054432787001132965, -0.009341452270746231, -0.05335765331983566, -0.026395557448267937, 0.0325244776904583, 0.02159285359084606, -0.04761501029133797, -0.012959574349224567, 0.021309584379196167, 0.018592773005366325, 0.027425628155469894, -0.0013640386750921607, 0.006798465270549059, 0.01606909930706024, -0.0035183345898985863, -0.02067866548895836, 0.038370124995708466, 0.036026716232299805, 0.03231846168637276, -0.033889319747686386, 0.006431502755731344, -0.03896241635084152, 0.0010292658116668463, -0.022545669227838516, 0.014021835289895535, -0.03654175251722336, -0.0022500602062791586, -0.003808042034506798, -0.011871562339365482, -0.001032484695315361, 0.0012384988367557526, -0.013854448683559895, 0.0010590412421151996, 0.014446739107370377, 0.009508838877081871, -0.01991898939013481, 0.020421147346496582, 0.012998201884329319, -0.020472651347517967, 0.004625660367310047, 0.014588373713195324, -0.009412269107997417, 0.06654255837202072, -0.021773114800453186, 0.012785750441253185, -0.02285468950867653, 0.024309664964675903, -0.00533705297857523, -0.0283784419298172, -0.02159285359084606, -0.01960996724665165, -0.017047667875885963, -0.024386920034885406, -0.0003941226750612259, 0.011105448007583618, -0.012695618905127048, -0.011330775916576385, 0.03950320556759834, 0.026022156700491905, -0.022803185507655144, -0.027168110013008118, 0.012605488300323486, -0.04277367889881134, 0.016184983775019646, 0.029176747426390648, -0.02111644484102726, -0.02021513320505619, 0.008993803523480892, 0.02091043069958687, -0.026936344802379608, 0.009792108088731766, 0.005922905635088682, 0.014408111572265625, -0.008652592077851295, -0.014021835289895535, -0.0075838943012058735, 0.014961774460971355, 0.004252259619534016, 0.018966173753142357, 0.017330937087535858, -0.0158244576305151, -0.03206094354391098, -0.0006450011860579252, 0.03170042112469673, -0.06819067150354385, -0.011163389310240746, 0.03226695954799652, -0.017820220440626144, 0.020871803164482117, -0.03360605239868164, 0.050782475620508194, -0.0442415289580822, 0.015064781531691551, 0.013056144118309021, -0.03141715005040169, -0.02345985546708107, -0.004696477670222521, -0.00465141236782074, -0.025790389627218246, -0.026524316519498825, 0.010648353956639767, -0.012148394249379635, 0.04223288968205452, 0.002602537628263235, 0.0063284956850111485, 0.010081815533339977, -0.00708817271515727, -0.04411276802420616, 0.0141892209649086, 0.018425386399030685, 0.002122910926118493, -0.0009077496360987425, 0.01910780742764473, -0.0459153950214386, -0.0037082538474351168, 0.00845301616936922, -0.017227929085493088, 0.007158990018069744, -0.036799270659685135, -0.024412671104073524, 0.0334000363945961, 0.015669947490096092, 0.016275113448500633, 0.017060542479157448, 0.027528634294867516, 0.016081975772976875, 0.020858928561210632, -0.0033992326352745295, -0.052894119173288345, 0.02492770552635193, -0.035151157528162, -0.02088467963039875, -0.030438583344221115, 0.018850291147828102, 0.009850049391388893, 0.03772633150219917, 0.013075457885861397, -0.0005878644878976047, -0.0100045595318079, -0.038421630859375, -0.027425628155469894, 0.0035923710092902184, 0.017459694296121597, -0.03309101611375809, 0.007886477746069431, 0.022249523550271988, 0.0015813191421329975, 0.006476568523794413, -0.0035666192416101694, 0.02868746407330036, -0.05227607861161232, -0.024773195385932922, -0.005288768094033003, 0.006058102007955313, 0.009090372361242771, -0.00807961542159319, 0.00628342991694808, -4.5568547648144886e-05, -0.00773196667432785, -0.006914348341524601, -0.002747391117736697, 0.019494084641337395, -0.0004611175099853426, 0.03159741312265396, 0.030902115628123283, 0.005626759957522154, -0.017524074763059616, -0.08843155205249786, -0.02362724207341671, 0.018785910680890083, -0.03543442487716675, -0.003695378080010414, -0.04341747239232063, -0.03319402411580086, -0.011317899450659752, -0.004606346599757671, 0.04274792596697807, -0.04970090091228485, -0.03898816928267479, -0.01864427700638771, -0.01820649579167366, 0.011324337683618069, -0.04109981283545494, 0.02134821191430092, -0.00014093054051045328, 0.009418707340955734, 0.002491482999175787, -0.014639876782894135, -0.06036213040351868, 0.036490246653556824, -0.040842294692993164, -0.020086374133825302, -0.0006739718955941498, -0.035588935017585754, -0.053666673600673676, 0.04200112447142601, -0.011601169593632221, -0.005613884422928095, 0.0367477647960186, 0.012483167462050915, 0.03623272851109505, -0.0021728049032390118, 0.010918747633695602, 0.0018702218076214194, -0.03739155828952789, 0.0025574718602001667, -0.012122642248868942, -0.014717132784426212, -0.006344590801745653, -0.03749456629157066, -0.010918747633695602, 0.034687623381614685, -0.006383218336850405, 0.017691461369395256, 0.04146033897995949, 0.04761501029133797, -0.027168110013008118, 0.01509053260087967, -0.026987846940755844, 0.010654792189598083, -0.00020209098875056952, 0.0011057163355872035, 0.007326376624405384, 0.0019780572038143873, 0.01864427700638771, -0.01525791920721531, -0.024992085993289948, -0.0022194799967110157, -0.014253600500524044, -0.005298424977809191, 0.008523833937942982, 0.003782290266826749, -0.0212838314473629, -0.05449073016643524, 0.0027602671179920435, 0.000724670710042119, -0.017923226580023766, 0.007081734947860241, -0.029897795990109444, -0.009083934128284454, -0.008678344078361988, -0.03383781760931015, 0.030026555061340332, 0.022442661225795746, 0.02540411427617073, 0.05019018426537514, 0.006061321124434471, 0.011253519915044308, 0.0031497625168412924, -0.018232248723506927, -0.034327100962400436, -0.025326859205961227, -0.0040043992921710014, 0.005700796376913786, -0.04828455671668053, 0.004171785432845354, 0.006122481543570757, -0.033992327749729156, -0.023073580116033554, -0.010043187066912651, -0.0023916950449347496, 0.01363555807620287, -0.01509053260087967, 0.021193699911236763, -0.01161404512822628, -0.07442259788513184, -0.02609941177070141, 0.013854448683559895, -0.022107888013124466, 0.0023852570448070765, -0.013661310076713562, 0.03909117728471756, 0.004203975200653076, -0.008665468543767929, -0.047640759497880936, 0.022030632942914963, -0.030773356556892395, -0.0019088494591414928, 0.0241937804967165, -0.0027538291178643703, -0.05917755141854286, -0.020395396277308464, -0.011208455078303814, 0.03721129894256592, -0.0040043992921710014, -0.025223851203918457, -0.009759917855262756, -0.02559725195169449, 0.0017173206433653831, 0.007319938391447067, -0.012444538995623589, -0.006650392897427082, 0.00031083181966096163, 0.020202258601784706, -0.007789908442646265, -0.0013720861170440912, -0.03414683789014816, -0.026627322658896446, -0.0024947021156549454, -0.010204136371612549, -0.03218970447778702, 0.001623970572836697, -0.01397033128887415, -0.020189382135868073, 0.004738324321806431, -0.0013946188846603036, -0.007075296714901924, 0.05279111489653587, -0.021399714052677155, 0.05552079901099205, -0.021335335448384285, 0.029305506497621536, -0.0020537031814455986, -0.026601571589708328, -0.023446980863809586, 0.00516966637223959, -0.011408030986785889, 0.027760399505496025, -0.01430510450154543, -0.001342310686595738, 0.009457334876060486, 0.027322620153427124, 0.017781592905521393, 0.030361328274011612, 0.0009721290552988648, -0.0003222993982490152, -0.005073097068816423, -0.02724536508321762, 0.02215939201414585, -0.03932294249534607, 0.017755839973688126, -0.025326859205961227, 0.02894498221576214, -0.02948576770722866, 0.0005572842201218009, -0.018464013934135437, 0.014987525530159473, 0.0013262158026918769, 0.03319402411580086, 0.008987365290522575, -0.018451137468218803, -0.0001340902381343767, 0.03741731122136116, -0.03705678507685661, 0.009405831806361675, 0.004451835993677378, -0.01743394322693348, -0.0400182381272316, 0.027863407507538795, -0.008060301654040813, 0.0029582337010651827, 0.042181387543678284, -0.00040961397462524474, -0.03582070395350456, 0.042825181037187576, 0.04565787687897682, -0.018077736720442772, 0.027657393366098404, -0.00031284368014894426, -0.02178599126636982, 0.013223529793322086, 0.00918694119900465, 0.024477049708366394, 0.04043026641011238, -0.004783390089869499, 0.047846775501966476, 0.028532953932881355, -0.018966173753142357, 0.007236245553940535, -0.006363904569298029, -0.025648755952715874, 0.027554385364055634, 0.017678584903478622, -0.004516215529292822, 0.005031250882893801, 0.0024576839059591293, 0.030541591346263885, -0.03193218633532524, 0.015373802743852139, 0.021747363731265068, 0.03229271247982979, 0.0024673407897353172, 0.028970733284950256, -0.003981866408139467, 0.014730008319020271, 0.007274873089045286, 0.01114407554268837, -0.03862764313817024, 0.005111725069582462, -0.011221330612897873, -0.011317899450659752, 0.019790230318903923, -0.006315619684755802, -0.014845890924334526, -0.023987766355276108, 0.0053467098623514175, 0.012405911460518837, 0.006940099876374006, -0.031005121767520905, -0.024760320782661438, 0.03406958281993866, 0.024374043568968773, 0.02358861453831196, -0.03852463886141777, 0.016043348237872124, 0.01743394322693348, 0.00927063450217247, 0.024786071851849556, 0.01064191572368145, -0.008813540451228619, 0.03226695954799652, 0.014099090360105038, -0.01469138078391552, 0.010944499634206295, 0.020253760740160942, 0.007770594675093889, 0.003402451751753688, -0.04040451720356941, 0.018013358116149902, 0.03458461910486221, -0.005076316185295582, 0.034558866173028946, -0.021064942702651024, 0.02268730290234089, 0.015708575025200844, 0.01491027045994997, 0.06880871206521988, -0.010217011906206608, 0.004574156831949949, 0.04681670665740967, -0.006273773033171892, -0.002465731231495738, -0.04843906685709953, -0.02670457772910595, 0.0326017327606678, -0.012637677602469921, -0.009457334876060486, 9.918452269630507e-05, -0.025223851203918457, -0.00845301616936922, 0.0333227813243866, 0.028738968074321747, 0.008910110220313072, 0.026962095871567726, 0.029099492356181145, 0.03476487845182419, 0.021000562235713005, -0.04691971093416214, 0.026962095871567726, 0.030309824272990227, -0.005111725069582462, 0.022610047832131386, -0.009611845947802067, -0.0024641219060868025, 0.045760881155729294, 0.020434023812413216, -0.00335094821639359, 0.022777434438467026, 0.026150915771722794, 0.0072877490893006325, -0.026421308517456055, 0.0026733549311757088, 0.027786152437329292, -0.01971297524869442, -0.047202982008457184, -0.011742804199457169, 0.019854608923196793, -0.0014163469895720482, 0.007564580533653498, -0.016455376520752907, 0.015515437349677086, 0.011292148381471634, -0.026627322658896446, 0.006759837735444307, -0.0033638239838182926, -0.004764076322317123, -0.008510957472026348, -0.029202498495578766, 0.020240886136889458, 0.008646154776215553, 0.0005387751734815538, 0.009804983623325825, -0.003553743241354823, -0.006631079129874706, -0.01033933274447918, -0.024618685245513916, -0.03731430321931839, -0.02542986534535885, 0.02492770552635193, -0.004616003483533859, -0.003605246776714921, -0.01843826286494732, -0.003293006680905819, 0.01033933274447918, -0.00893586128950119, -0.005108505953103304, -0.008852168917655945, -0.0011451486498117447, 0.009598969481885433, 0.016648514196276665, -0.0013407011283561587, -0.006045226473361254, -0.013313661329448223, 0.004409989342093468, -0.012740684673190117, -0.012257839553058147, -0.017163550481200218, 0.001841251039877534, -0.022378282621502876, 0.0019523055525496602, 0.0004373776027932763, 0.02272593043744564, 0.030799107626080513, -0.030696101486682892, 0.011974569410085678, 0.00657635647803545, -0.014755760319530964, 0.024077897891402245, -0.027760399505496025, 0.0375460684299469, -0.03530566766858101, 0.0163008663803339, 0.041846614331007004, 0.045168593525886536, 0.015064781531691551, 0.006099948659539223, 0.003272083355113864, 0.027193861082196236, -0.021502722054719925, 0.04465355724096298, -0.04761501029133797, -0.029073739424347878, 0.023112207651138306, -0.013506799936294556, 0.015425305813550949, -0.015142036601901054, 0.04823305085301399, -0.016790149733424187, 0.02609941177070141, -0.01847689040005207, 0.022635798901319504, -0.015837334096431732, -0.009624721482396126, -0.004616003483533859, 0.0025413772091269493, 0.0009447677875868976, -0.00025973067386075854, -0.021605728194117546, 0.00994018092751503, 0.011292148381471634, -0.008176184259355068, -0.04187236726284027, -0.006083854008466005, 0.04789827764034271, -0.011671986430883408, 0.02402639389038086, 0.034352850168943405, 0.009238445200026035, -0.00960540771484375, 0.002309611300006509, 0.012483167462050915, 0.012534670531749725, -0.00823412649333477, 0.017163550481200218, -0.010229887440800667, 0.052224576473236084, 0.006573137361556292, -0.019455457106232643, -0.02302207611501217, 0.045065585523843765, -0.009335014037787914, -0.023369723930954933, -0.026627322658896446, 0.010551785118877888, -0.04122857376933098, -0.022236647084355354, 0.009508838877081871, 0.023614367470145226, 0.006212612614035606, 0.008253440260887146, -0.04735749214887619, -0.019429704174399376, 0.002122910926118493, -0.027734648436307907, -0.028198180720210075, 0.03414683789014816, 0.02593202516436577, 0.014897394925355911, -0.00555594265460968, -0.0040076179429888725, -0.008440140634775162, 0.00764827337116003, -0.008266315795481205, 0.002201775787398219, -0.0015781002584844828, -0.0007315110415220261, 0.023305345326662064, -0.009071058593690395, -0.006476568523794413, -0.0221207644790411, 0.0003488559159450233, -0.0029791570268571377, -0.0074165076948702335, 0.007950856350362301, -0.029563024640083313, 0.015528312884271145, -0.006045226473361254, 0.028738968074321747, -0.02573888748884201, 0.008086053654551506, 0.0241937804967165, -0.004445398226380348, -0.03360605239868164, 0.028198180720210075, 0.03551167994737625, 0.07220794260501862, 0.002559081418439746, -0.05804447457194328, 0.023871883749961853, -0.009785669855773449, 0.024219533428549767, -0.0029163870494812727, 0.010133318603038788, -0.03175192326307297, 0.040507521480321884, -0.007210493553429842, 0.0475120022892952, -0.0056943586096167564, -0.00041886852704919875, -0.005301644094288349, -0.019197938963770866, -0.011150513775646687, 0.03208669647574425, 0.0065699187107384205, 0.025017837062478065, 0.01830950379371643, 0.019300946965813637, -4.981859456165694e-05, -0.020060623064637184, -0.0022613266482949257, 0.006650392897427082, -0.010680543258786201, -0.019185062497854233, 0.026292549446225166, 0.03883365914225578, 0.021644357591867447, -0.020073499530553818, -0.022030632942914963, 0.02891922928392887, -0.030876364558935165, 0.019288070499897003, -0.011639797128736973, -0.01586308516561985, -0.019532712176442146, -0.011813621036708355, 0.018592773005366325, 0.015219291672110558, -0.006895034573972225, -0.0009141875780187547, 0.029176747426390648, 0.006766275502741337, 0.024760320782661438, 0.0016376511193811893, 0.005015155766159296, 0.01615923084318638, 0.018953297287225723, -0.002147053135558963, -0.02439979463815689, -0.015901712700724602, -0.018361007794737816, -0.0019941520877182484, -0.026781832799315453, 0.05034469813108444, 0.012154832482337952, 0.006476568523794413, -0.024103650823235512, 0.014317980036139488, -0.0358722060918808, 0.007532390765845776, 0.014253600500524044, -0.007577456068247557, -0.02626679837703705, -0.019558463245630264, -0.011813621036708355, 0.038241367787122726, -0.007880039513111115, 0.007468011230230331, 0.0023852570448070765, 0.012843691743910313, 0.012779312208294868, 0.020240886136889458, -0.0077963462099432945, 0.011923066340386868, 0.011414469219744205, 0.018592773005366325, 0.013867324218153954, 0.0012224039528518915, -0.023807505145668983, -0.008594650775194168, -0.012740684673190117, -0.008749161846935749, -0.0059486571699380875, -0.00019736311514861882, -0.038910914212465286, 0.03376056253910065, -0.02486332692205906, 0.009161189198493958, 0.04079079255461693, 0.036490246653556824, 0.02061428688466549, 0.0024689503479748964, 0.007274873089045286, -0.002155100693926215, 0.039915233850479126, 0.02044690027832985, -0.001405080547556281, 0.013867324218153954, -0.031236888840794563, 0.007165427785366774, -0.009180503897368908, 0.017897475510835648, -0.041383083909749985, -0.0309278666973114, -0.0030467554461210966, 0.03126263990998268, -0.011343651451170444, -0.004564499948173761, 0.01033933274447918, 0.00717186601832509, -0.0066246408969163895, -0.02473456785082817, -0.015888838097453117, 0.021438343450427055, 0.0025993185117840767, -0.04928887262940407, -0.018348131328821182, 0.010114004835486412, 0.020575659349560738, 0.0075967698357999325, -0.007126800250262022, -0.016944659873843193, -0.015837334096431732, 0.012573298066854477, 0.009141875430941582, -0.008613964542746544, -0.035151157528162, 0.0010896214516833425, 0.029202498495578766, -0.0042908876203000546, 0.017279433086514473, 0.04709997400641441, -0.0014340513153001666, -0.041692104190588, -0.0005403846735134721, -0.012972450815141201, 0.009502400644123554, 0.013223529793322086, -0.022429784759879112, 0.0005089996848255396, 0.009998122230172157, -0.001277126488275826, 0.018515517935156822, -0.010925184935331345, 0.012644115835428238, 0.006849968805909157, 0.016893155872821808, 0.02891922928392887, -0.012644115835428238, 0.0008667077636346221, 0.010873681865632534, 0.035357169806957245, -0.013442420400679111, -0.028017917647957802, -0.009392955340445042, -0.025790389627218246, 0.006418626755475998, 0.0003703827678691596, -0.004957214463502169, 0.014601249247789383, 0.036490246653556824, -0.01615923084318638, -0.015837334096431732, 0.03149440512061119, 0.0038692024536430836, -0.009850049391388893, -0.03651599958539009, -0.021258080378174782, 0.021863246336579323, 0.020163631066679955, -0.012154832482337952, -0.0279406625777483, -0.0064025321044027805, -0.010693419724702835, 0.016004720702767372, 0.0038466695696115494, -3.6615787394111976e-05, -0.03226695954799652, 0.04578663408756256, -0.026550067588686943, -0.003038708120584488, 0.006183641962707043, 0.02871321514248848, 0.0006272968603298068, -0.0025252823252230883, -0.039709217846393585, 0.006611764896661043, -0.01984173245728016, 0.02540411427617073, -0.0020794549491256475, -0.0019909332040697336, 0.038601893931627274, 0.026627322658896446, 0.04704847186803818, 0.03731430321931839, 0.022532792761921883, 0.006959414109587669, -0.03700528293848038, 0.007641835603863001, -0.009032431058585644, -0.010429464280605316, 0.013210654258728027, 0.009663349017500877, 0.029511520639061928, -0.01663563959300518, -0.005160009488463402, 0.008420826867222786, -0.039580460637807846, 0.013139837421476841, 0.004770514089614153, -0.013841572217643261, 0.02667882665991783, 0.03365755453705788, -0.005507658235728741, -0.027889158576726913, -0.03517690673470497, -0.03530566766858101, 0.022481288760900497, -0.006631079129874706, -0.013416668400168419, -0.0037018158473074436, 0.048851095139980316, 0.026189543306827545, -0.015708575025200844, 0.00815043319016695, -0.0020939402747899294, 0.018592773005366325, -0.0037726331502199173, -0.006212612614035606, 0.00021084255422465503, -0.013983206823468208, 0.004278011620044708, 0.004030150827020407, -0.015180664137005806, 0.006090291775763035, -0.014730008319020271, -0.0038273558020591736, 0.05861101299524307, 0.030129563063383102, 0.012541108764708042, -0.015335175208747387, 0.0660790205001831, 0.010307143442332745, 0.006714771967381239, -0.03370905667543411, 0.002454464789479971, 0.0009375251247547567, 0.01948120817542076, -0.018567021936178207, -0.03337428346276283, 0.008639716543257236, -0.044267281889915466, -0.011472410522401333, -0.021747363731265068, 0.001475093187764287, 0.03700528293848038, 0.0008385417750105262, -0.02369162254035473, 0.016043348237872124, -0.016455376520752907, -0.007313500624150038, 0.030747605487704277, -6.070777089917101e-05, 0.032910753041505814, -0.01740819215774536, -0.0034056706354022026, -0.02098768763244152, 0.013725689612329006, 0.011247082613408566, -0.011079696007072926, 0.020833175629377365, 0.021361086517572403, 0.010229887440800667, -0.00371469184756279, -0.019661471247673035, -0.011350089684128761, -0.007403631694614887, 0.024142278358340263, 0.006080634891986847, -0.047743767499923706, -0.004715791437774897, -0.002081064274534583, -0.03700528293848038, 0.00845301616936922, -0.00012433272786438465, -0.010931623168289661, -0.02329246886074543, 0.003663188312202692, 0.03296225517988205, -0.011317899450659752, 0.015360926277935505, 0.027786152437329292, 0.02011212706565857, -0.006470130290836096, 0.012257839553058147, -0.005024812649935484, -0.056808389723300934, -0.01452399417757988, -0.007242683321237564, 0.008530271239578724, 0.005819898564368486, 0.040481772273778915, -0.01649400405585766, 0.046765200793743134, -0.01485876739025116, -0.02011212706565857, -0.006537728942930698, -0.03293650597333908, -0.010886557400226593, 0.008420826867222786, 0.020897556096315384, -0.019365325570106506, 0.01250248122960329, -0.012380160391330719, -0.009611845947802067, 0.01615923084318638, 0.01293382328003645, -0.042953941971063614, -0.01474288385361433, 0.01216770801693201, 0.08116955310106277, -0.02902223728597164, 0.014807263389229774, 0.014833015389740467, 0.01833525486290455, 0.023884760215878487, 0.025107968598604202, 0.004136377014219761, 0.04612140730023384, -0.009862924925982952, -0.0031433245167136192, -0.022249523550271988, 0.0035923710092902184, 0.015592692419886589, 0.037597574293613434, 0.008517395704984665, -0.02356286346912384, 0.012772873975336552, -0.005658949725329876, 0.003521553473547101, -0.005011936649680138, -0.02701359987258911, 0.030464336276054382, 0.02540411427617073, 0.02349848300218582, -0.001214356510899961, 0.04699696600437164, 0.017292309552431107, 0.017382439225912094, -0.011317899450659752, 0.007609645836055279, 0.0006023498135618865, 0.03623272851109505, -0.02948576770722866, -0.010564660653471947, 0.011993883177638054, -0.052327580749988556, -0.019700098782777786, 0.021309584379196167, -0.010320018976926804, 0.006914348341524601, 0.03721129894256592, -0.0065699187107384205, -0.015154912136495113, -0.010365084744989872, -0.03365755453705788, -0.00035971993929706514, -0.011234206147491932, 0.023034952580928802, 0.008807103149592876, 0.004590251948684454, -0.009727728553116322, -0.014974649995565414, -0.024515679106116295, 0.01881166361272335, -0.03373480960726738, 0.015476809814572334, -0.034018076956272125, 0.012135518714785576, -0.029125243425369263, -0.026936344802379608, -0.008974489755928516, 0.0076804631389677525, 0.0038981731049716473, 0.003940019756555557]\n"
     ]
    }
   ],
   "source": [
    "res = client.embeddings.create(\n",
    "    input=corpus[\"train\"][0][\"contents\"],\n",
    "    model=\"text-embedding-3-small\",\n",
    ")\n",
    "print(res.data[0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "from chromadb import EphemeralClient\n",
    "from chromadb.config import Settings\n",
    "from chromadb.types import Collection\n",
    "from chromadb.utils.embedding_functions.openai_embedding_function import (\n",
    "    OpenAIEmbeddingFunction,\n",
    ")\n",
    "\n",
    "try:\n",
    "    api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "except KeyError:\n",
    "    raise ValueError(\"No API key.\")\n",
    "\n",
    "chroma_client = EphemeralClient(Settings(anonymized_telemetry=False))\n",
    "embedding_fn = OpenAIEmbeddingFunction(api_key, model_name=\"text-embedding-3-small\")\n",
    "\n",
    "papers_collection = chroma_client.create_collection(\n",
    "    name=\"papers\", embedding_function=embedding_fn, get_or_create=True\n",
    ")\n",
    "\n",
    "\n",
    "def embed(\n",
    "    coll: Collection, docs: Iterable[str], ids: Iterable[str], batch_size: int = 2048\n",
    ") -> None:\n",
    "    \"\"\"Embeds a list of documents and update or insert them into a collection.\"\"\"\n",
    "    for i in range(0, len(docs), batch_size):\n",
    "        coll.upsert(documents=docs[i : i + batch_size], ids=ids[i : i + batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed(papers_collection, corpus[\"train\"][\"contents\"], corpus[\"train\"][\"doc_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['c1c0ecba-3d50-4cd3-abac-9487f1b7fc44',\n",
       "   '639765ad-0444-4d65-8212-0270681d2296',\n",
       "   'fd44285b-cf3c-4c3d-be52-a1930de88f89',\n",
       "   '349ed82f-e133-404b-b1f6-3bbf1000bb68',\n",
       "   'f88bfdf4-e8aa-4faf-a3cc-e2976a8fe93d',\n",
       "   'cb798935-71bd-4f9d-8078-0443913ec8c5',\n",
       "   'f3a2805a-2678-454b-8b64-e29763cf0a74',\n",
       "   '50dddb08-9526-40fc-baae-0c3afcd67b8a',\n",
       "   'a256607e-d318-4ac1-8a43-24184ce5b743',\n",
       "   '5fb6b0d9-e792-46a8-923c-918330407e61']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['## Unhealthy Conversation Prompts Prompt For Q-0S And Lm Scenarios\\n### Text:\\n\\n<text>',\n",
       "   '## Unhealthy Conversation Prompts Prompt For Q-0S And Lm Scenarios\\n### Text:\\n\\n<text>',\n",
       "   '## Unhealthy Conversation Prompts Prompt For Q-0S And Lm Scenarios\\n### Text:\\n\\n<text>',\n",
       "   '## Unhealthy Conversation Prompts Prompt For Q-0S And Lm Scenarios\\n### Text:\\n\\n<text>',\n",
       "   '## Unhealthy Conversation Prompts Prompt For Q-0S And Lm Scenarios\\n### Text:\\n\\n<text>',\n",
       "   '## Unhealthy Conversation Prompts Prompt For Q-0S And Lm Scenarios\\n### Response:\\n\\nCategorize the following text for the specified user by selecting the most appropriate label from the provided list. Labels represent different types of communication styles or tones, where each category denotes a specific attitude or approach that someone might exhibit when communicating with others. Analyze text carefully to make an accurate categorization. Please compose your response as a list of chosen labels, separated by commas. ### User ID:\\n<user ID>',\n",
       "   \"## Unhealthy Conversation Prompts Prompt For Q-0S And Lm Scenarios\\n### Example Response:\\n\\n<user's annotations for the example>\",\n",
       "   '## E.2. Low-Quality Samples Identified By Ask-Llm\\n\\n14%\\n47.01%  \\nEventsThis is how you can go ice skating with real penguinsGrab your tickets before they sell out! Can you spot anyone you know in these fun pics? EventsHow do I get tickets for Wimbledon 2018?  \\nASK-LLM\\nPerplexity Filtering\\nSmall\\nBase\\nLarge\\nXL\\nXXL\\nSmall\\nBase\\nLarge\\nXL\\nXXL\\n2.17%\\n1.11%\\n3.75%\\n2.0%\\n5.31%\\n92.49%\\n89.88%\\n86.79%\\n97.04%\\n96.78%  \\nThat I don\\'t make you happy? We can start all over some day? Somewhere, are you dreaming of me? Won\\'t you come back home to me?  \\nASK-LLM\\nPerplexity Filtering\\nSmall\\nBase\\nLarge\\nXL\\nXXL\\nSmall\\nBase\\nLarge\\nXL\\nXXL\\n0.06%\\n0.04%\\n0.08%\\n0.11%\\n0.07%\\n68.86%\\n51.15%\\n44.08%\\n35.81%\\n19.28%  \\n? , ? , ? , ? , ? ? , ? ? . (1395). ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? . ? ? ? ? , 26(2), 145-159. ? ? ; ? ? ; ? ? ? ? . \" ? ? ?\\n? ? ? ? ? ? ? ? ? ? ? ? ? ? \". ? ? ? ? , 26, 2, 1395, 145-159. ? , ? , ? , ? , ? ? , ? ? . (1395). \\' ? ? ? ? ? ? ? ? ? ? ? ? ?\\n? ? ? ? \\', ? ? ? ? , 26(2), pp. 145-159. ? , ? , ? , ? , ? ? , ? ? . ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? . ? ? ? ? , 1395; 26(2):\\n145-159. ? ? ? ? ? ? ? ? ? ? ? ? ? BHT ? ? ? ? ? ? ? DPPH ? ? ? ? ? ? ? ? ? ? ? ? . ? ? ? ? ? ? ? ? ? ? ? ?',\n",
       "   '## Unhealthy Conversation Prompts Prompt For Q-0S And Lm Scenarios\\n\\nCategorize the following text by selecting the most appropriate label from the provided list. Labels represent different types of communication styles or tones, where each category denotes a specific attitude or approach that someone might exhibit when communicating with others.  \\nAnalyze text carefully to make an accurate categorization.  \\nPlease compose your response as a list of chosen labels, separated by commas. ### Text:\\n<text>',\n",
       "   \"## Unhealthy Conversation Prompts Prompt For Q-0S And Lm Scenarios\\n### Example 1 Response:\\n\\n<user's annotations for the first example>\"]],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[None, None, None, None, None, None, None, None, None, None]],\n",
       " 'distances': [[1.48362135887146,\n",
       "   1.48362135887146,\n",
       "   1.48362135887146,\n",
       "   1.48362135887146,\n",
       "   1.48362135887146,\n",
       "   1.4923924207687378,\n",
       "   1.4939191341400146,\n",
       "   1.495236873626709,\n",
       "   1.5064440965652466,\n",
       "   1.5076653957366943]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_collection.query(query_texts=[\"Hello, how are you today?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Does the Turing Test assess a machine's ability to exhibit intelligent behavior equivalent to that of a human?\n",
      "1 Is the oa_temp or the zone_occ the most impactful feature according to the Shapley values?\n",
      "2 What is the performance percentage increase observed in the navigational prompt suffix attack scenario when using VELMA-FT?\n",
      "3 What are essential components of evaluating large language models (LLMs)?\n",
      "4 How many errors were there in the Inference phase as per the document?\n",
      "5 What is the meaning of PLP-former in the context of this text?\n",
      "6 How does the Qmsum value vary between the first and the third entries?\n",
      "7 What is the purpose of using the torch.einsum function in the provided text?\n",
      "8 What is the result of applying the PAL attack against GPT-3.5-Turbo?\n",
      "9 What is the process to deceive the test function as described?\n",
      "10 What leads to a greater decrease in performance in deploying LLMs/VLMs in robotics according to the experiment?\n",
      "11 Why has the accuracy of the models not reached 100% after adjusting and reordering steps?\n",
      "12 How significant do you believe the challenge of proper prompt engineering is in accurately evaluating artificial intelligence models?\n",
      "13 Is P7 a beginner who slightly disagrees with the effectiveness of LLM-powered editing functions for presentations?\n",
      "14 Is the Kendall's Tau correlation coefficient for Figure 5 .18 or .20?\n",
      "15 In the HotPotQA dataset, which model variation of HGOT achieved the highest EM score in the \"Medium\" category, and how did it compare to the second-best performers?\n",
      "16 What types of attacks are Large Language Models (LLMs) vulnerable to in urban navigation?\n",
      "17 What mathematical formula is used to formalize the jointable attack?\n",
      "18 What does \"Perception Attack\" mean in the context of robotics?\n",
      "19 How similar are ProbLog in-context examples and ProbLog queries in teaching the syntax and structure necessary for writing ProbLog code?\n",
      "20 What method boosts the performance of MLLM in explainable driving without further training effort?\n",
      "21 What is the result of having all sides of a quadrilateral equal to 5 units?\n",
      "22 What is the procedure to underscore possible causes of agent behaviors in LLM-Based Autonomous Systems?\n",
      "23 What enables the improvement of diagnostic accuracy by combining insights from multiple large language models?\n",
      "24 Why has Syntaxshap not been widely adopted in all text generation applications?\n",
      "25 How important do you consider the identification and optimization of a steering vector in unifying causal representation learning with foundation models?\n",
      "26 Is the text providing detailed results of an experiment related to LLMs-based navigation security?\n",
      "27 Is the evaluation based on cosine similarity or exact data replication?\n",
      "28 What are the main contributions of the research on the butterfly effect of model editing as mentioned in the introduction?\n",
      "29 What are the components of Agentlens's visual analysis for studying agent behaviors in LLM-based autonomous systems?\n",
      "30 What is the highest percentage result reported?\n",
      "31 What does \"MMs\" stand for in the context of evaluating models on geometry problem-solving?\n",
      "32 How does the FBank acoustic feature compare to Whisper-tiny in terms of model size?\n",
      "33 What does the term \"Longheads\" refer to in the context of this document?\n",
      "34 What is the result of the Example Generation on Forget Set?\n",
      "35 What is the process to interpret Kendall's Tau Correlation Coefficient for Figure 5 in relation to cross-lingual vocabulary adaptation efficiency?\n",
      "36 What makes Hgot useful for retrieval-augmented in-context learning in factuality evaluation?\n",
      "37 Why has the model editing not led to the permanent solution for the collapse of large language models?\n",
      "38 How do you assess the significance of Kendall's Tau Correlation Coefficient for evaluating cross-lingual vocabulary adaptation in generative models?\n",
      "39 Does the model primarily use the graph to generate responses?\n",
      "40 Is the focal point Turing patterns or fractal geometry?\n",
      "41 What is the source of the prompts for the HPSv2 dataset used in the ablation study?\n",
      "42 What are the datasets mentioned in the detailed results?\n",
      "43 What metrics are used to benchmark the TOPGUN approach in tool planning?\n",
      "44 What is the meaning of AgentEval in the context of LLM-powered applications?\n",
      "45 How does the effectiveness of the new LLM-driven discrete prompt optimization framework compare to human-engineered prompts in multi-step tasks?\n",
      "46 What is the purpose of mixing sample and token level loss in the described ablation study?\n",
      "47 What is the result of analyzing the given Qmsum data?\n",
      "48 What is the procedure to minimize academic procrastination according to the study?\n",
      "49 What allows the indexing and categorization of these digital media artifacts?\n",
      "50 Why is there no explanation on how the backward and forward passes affect the model's understanding of embeddings in few-shot prompts in the text?\n",
      "51 How important do you think is genuine reasoning in AI development compared to technical optimization?\n",
      "52 Is the subject related to the acceleration of lightweight models on the edge?\n",
      "53 Is the Transformer model initially used for machine translation or facial recognition?\n",
      "54 What are the two steps to be followed in responding to a prompt after receiving potentially applicable feedback according to the instructions?\n",
      "55 What are the datasets used for natural language inference, commonsense, and sentiment analysis in the training and evaluation processes?\n",
      "56 How many countries do the Andes cover?\n",
      "57 What is the meaning of \"AmazonCounterfactualClassification\"?\n",
      "58 How similar is the process of data processing in the Sequential Recommendation (SR) task to traditional sequential recommendation tasks?\n",
      "59 How does Biomistral ensure relevance and prevent irrelevant tokens or hallucinations during inference?\n",
      "60 What is the consequence of using HGOT for fact retrieval and reasoning?\n",
      "61 What is the procedure to integrate Triple into end-to-end pipelines for prompt learning under a limited budget?\n",
      "62 What enables the constraint of raw material usage not to exceed available amounts in the optimization model?\n",
      "63 Why isn't there any data provided for hours of Data (h) besides Jukebox in the table?\n",
      "64 How do you rate the effectiveness of Vicuna as an LLM and fine-tuned HuBERT as a speech encoder for ASR tasks compared to other models?\n",
      "65 Is the METEOR score used for evaluating the semantic similarity in MC tasks?\n",
      "66 Is the NPE defense experiment showing a higher success rate for upward or downward navigation in LLMs-based navigation?\n",
      "67 What is the count of training data for AVE used in the Task section and what year is associated with the PM data for the OOD Test?\n",
      "68 What are the data sources mentioned in improving driving explanations?\n",
      "69 What is the value of Kendall's Tau Correlation Coefficient for Figure 5 in the study?\n",
      "70 What is Kendall's Tau correlation coefficient?\n",
      "71 How similar are the performance metrics of diminutive language models in clinical tasks?\n",
      "72 What contributed to AgentLens providing a significant improvement in exploring the cause of agent behaviors over the baseline?\n",
      "73 What is the consequence of a Navigational Prompt Suffix (NPS) attack on Large Language Models (LLMs) for navigation in urban environments?\n",
      "74 What is the process to reduce the computational cost of finetuning in model distillation?\n",
      "75 What enables the efficient routing of tokens in the V-MoE model?\n",
      "76 Why don't LLMs provide accurate explanations for incorrect predictions?\n",
      "77 What do you think about the use of \"Forget Set\" in data generation?\n",
      "78 Is Linqi Song affiliated with City University of Hong Kong?\n",
      "79 Is the feature about 'generating text to address an in-line prompt' or 'creating a comprehensive database for text analysis'?\n",
      "80 What is the purpose of the LAMBADA metric developed by OpenAI, and how does it differ in its approach to assessing Large Language Models (LLMs)?\n",
      "81 What are the names of the models mentioned in the main results section?\n",
      "82 How many languages were primarily focused on in the study?\n",
      "83 What is Kendall's Tau correlation coefficient?\n",
      "84 How similar are the metrics used to evaluate Llama2-13B-chat and Vicuna-13B-v1.5-16K models?\n",
      "85 What has led to the significant attention towards multimodal variants based on Large Language Models?\n",
      "86 What is the significance of Kendall's Tau correlation coefficient in assessing the performance of the vocabulary adaptation?\n",
      "87 What is the procedure to integrate Triple into end-to-end pipelines for prompt learning under a limited budget?\n",
      "88 What makes the GRACE framework able to perform generative cross-modal retrieval?\n",
      "89 Why doesn't the text provide a clear explanation on how self-alignment mitigates hallucinations in LLMs?\n",
      "90 In the context of machine learning models, how important do you think precision is in computations, such as using FP32 versus BF16?\n",
      "91 Is the angle BAC equal to 30 degrees?\n",
      "92 Is the text about a musical performance or a scientific experiment?\n",
      "93 What is the purpose of the evaluation framework mentioned in the document?\n",
      "94 What are some components of the legal evaluation framework described in the document?\n",
      "95 What percentage improvement in model performance was observed when comparing GPT-4 and GPT-4 plus RAG?\n",
      "96 What does the term \"black-box\" mean in the context of AI-generated text detection?\n",
      "97 How similar are the studies focusing on AI in video editing and AI in text compression?\n",
      "98 What are the limitations observed in the study on LLMs and MMs in solving geometry problems?\n",
      "99 What is the result of Bryan Wang's internship at Meta Reality Labs - Research?\n"
     ]
    }
   ],
   "source": [
    "for i, q in enumerate(qa[\"train\"][:100][\"query\"]):\n",
    "    print(i, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What makes the GRACE framework able to perform generative cross-modal retrieval?\n",
      "Dateset answer: GRACE assigns unique identifiers to images and comprises two training steps: learning to memorize the associations between visual content and their identifiers, and learning to retrieve the identifier of a relevant image given a textual query.\n",
      "Model answer with context: GRACE assigns unique identifiers to images in the dataset, enabling the model to learn mappings from images to identifiers for effective visual memory and generation, supporting generative cross-modal retrieval.\n",
      "Model answer without context: The GRACE framework combines generative modeling and discriminative learning to effectively perform cross-modal retrieval tasks.\n"
     ]
    }
   ],
   "source": [
    "model = \"gpt-3.5-turbo\"\n",
    "\n",
    "question = qa[\"train\"][88][\"query\"]\n",
    "answer = qa[\"train\"][88][\"generation_gt\"][0]\n",
    "\n",
    "context = \"\\n\\n\".join(\n",
    "    \"\\n\".join(doc)\n",
    "    for doc in papers_collection.query(query_texts=[question], n_results=1)[\"documents\"]\n",
    ")\n",
    "message = question\n",
    "\n",
    "\n",
    "# message = f\"\"\"Question:\n",
    "# {question}\n",
    "\n",
    "# Context:\n",
    "# {context}\"\"\"\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Dateset answer: {answer}\")\n",
    "\n",
    "completion_rag = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant, answer in one sentence.\",\n",
    "        },\n",
    "        {\"role\": \"assistant\", \"content\": context},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"Model answer with context: {completion_rag.choices[0].message.content}\")\n",
    "\n",
    "completion_norag = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant, answer in one sentence.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"Model answer without context: {completion_norag.choices[0].message.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Generative Cross-Modal Retrieval: Memorizing Images In Multimodal Language Models For Retrieval And Beyond\n",
      "## 3.2 Overview\n",
      "\n",
      "In this work, we present GRACE, a novel generative cross-modal retrieval framework, as illustrated in Figure 2. As previously discussed, addressing the challenges of visual memory and visual recall is essential for generative cross-modal retrieval. Towards this objective, GRACE assigns **unique** identifiers to images in the dataset DI. This strategy allows the model to learn mappings from images to their respective identifiers, facilitating visual memory. Moreover, the model could generate identifiers as retrieval results rather than generate real images. Representing images as identifiers underpins our training scheme, which is divided into two core steps: \"learning to memorize\" and \"learning to retrieve\". The two training steps are designed to enable the model to effectively memorize images in parameters and subsequently learn to recall them in response to textual queries.\n"
     ]
    }
   ],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from waterllmarks.pipeline import QueryAugmentation, ExecConfig\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "qa = QueryAugmentation(\n",
    "    config=ExecConfig(\n",
    "        llm=llm,\n",
    "    )\n",
    ")\n",
    "\n",
    "qa(\n",
    "    {\n",
    "        \"query\": \"What is the capital of France?\",\n",
    "    }\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
